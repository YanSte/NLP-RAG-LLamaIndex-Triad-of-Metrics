{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1ChKW1kEIUcUVDDTWjpA5Tf_ib3Hhp3uS","timestamp":1695164681916}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lesson 2: RAG Triad of metrics","metadata":{"id":"X6-q-gTUaZU7","tags":[]}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"height":47},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import utils\n\nimport os\nimport openai\nopenai.api_key = utils.get_openai_api_key()","metadata":{"height":98},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#!pip install python-dotenv\n\n\nimport os\nfrom dotenv import load_dotenv, find_dotenv\n\nimport numpy as np\nimport nest_asyncio\n\nnest_asyncio.apply()\n\n\ndef get_openai_api_key():\n    _ = load_dotenv(find_dotenv())\n\n    return os.getenv(\"OPENAI_API_KEY\")\n\n\ndef get_hf_api_key():\n    _ = load_dotenv(find_dotenv())\n\n    return os.getenv(\"HUGGINGFACE_API_KEY\")\n\nfrom llama_index import ServiceContext, VectorStoreIndex, StorageContext\nfrom llama_index.node_parser import SentenceWindowNodeParser\nfrom llama_index.indices.postprocessor import MetadataReplacementPostProcessor\nfrom llama_index.indices.postprocessor import SentenceTransformerRerank\nfrom llama_index import load_index_from_storage\nimport os\n\n\ndef build_sentence_window_index(\n    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n):\n    # create the sentence window node parser w/ default settings\n    node_parser = SentenceWindowNodeParser.from_defaults(\n        window_size=3,\n        window_metadata_key=\"window\",\n        original_text_metadata_key=\"original_text\",\n    )\n    sentence_context = ServiceContext.from_defaults(\n        llm=llm,\n        embed_model=embed_model,\n        node_parser=node_parser,\n    )\n    if not os.path.exists(save_dir):\n        sentence_index = VectorStoreIndex.from_documents(\n            [document], service_context=sentence_context\n        )\n        sentence_index.storage_context.persist(persist_dir=save_dir)\n    else:\n        sentence_index = load_index_from_storage(\n            StorageContext.from_defaults(persist_dir=save_dir),\n            service_context=sentence_context,\n        )\n\n    return sentence_index\n\n\ndef get_sentence_window_query_engine(\n    sentence_index,\n    similarity_top_k=6,\n    rerank_top_n=2,\n):\n    # define postprocessors\n    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n    rerank = SentenceTransformerRerank(\n        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n    )\n\n    sentence_window_engine = sentence_index.as_query_engine(\n        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n    )\n    return sentence_window_engine\n\n\nfrom llama_index.node_parser import HierarchicalNodeParser\n\nfrom llama_index.node_parser import get_leaf_nodes\nfrom llama_index import StorageContext\nfrom llama_index.retrievers import AutoMergingRetriever\nfrom llama_index.indices.postprocessor import SentenceTransformerRerank\nfrom llama_index.query_engine import RetrieverQueryEngine\n\n\ndef build_automerging_index(\n    documents,\n    llm,\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    save_dir=\"merging_index\",\n    chunk_sizes=None,\n):\n    chunk_sizes = chunk_sizes or [2048, 512, 128]\n    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n    nodes = node_parser.get_nodes_from_documents(documents)\n    leaf_nodes = get_leaf_nodes(nodes)\n    merging_context = ServiceContext.from_defaults(\n        llm=llm,\n        embed_model=embed_model,\n    )\n    storage_context = StorageContext.from_defaults()\n    storage_context.docstore.add_documents(nodes)\n\n    if not os.path.exists(save_dir):\n        automerging_index = VectorStoreIndex(\n            leaf_nodes, storage_context=storage_context, service_context=merging_context\n        )\n        automerging_index.storage_context.persist(persist_dir=save_dir)\n    else:\n        automerging_index = load_index_from_storage(\n            StorageContext.from_defaults(persist_dir=save_dir),\n            service_context=merging_context,\n        )\n    return automerging_index\n\n\ndef get_automerging_query_engine(\n    automerging_index,\n    similarity_top_k=12,\n    rerank_top_n=6,\n):\n    base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n    retriever = AutoMergingRetriever(\n        base_retriever, automerging_index.storage_context, verbose=True\n    )\n    rerank = SentenceTransformerRerank(\n        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n    )\n    auto_merging_engine = RetrieverQueryEngine.from_args(\n        retriever, node_postprocessors=[rerank]\n    )\n    return auto_merging_engine\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from trulens_eval import Tru\n\ntru = Tru()\ntru.reset_database()","metadata":{"height":81,"id":"IBfdyn3MaZU9"},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":"ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n\nðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"}]},{"cell_type":"code","source":"from llama_index import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\n    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n).load_data()","metadata":{"height":98,"id":"wMvq1q8yaZU-"},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from llama_index import Document\n\ndocument = Document(text=\"\\n\\n\".\\\n                    join([doc.text for doc in documents]))","metadata":{"height":81,"id":"sY8Oui4taZU-"},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from utils import build_sentence_window_index\n\nfrom llama_index.llms import OpenAI\n\nllm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n\nsentence_index = build_sentence_window_index(\n    document,\n    llm,\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    save_dir=\"sentence_index\"\n)","metadata":{"height":217},"execution_count":6,"outputs":[{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package punkt to /tmp/llama_index...\n\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b77ab102c7949c59025c7983140b14f","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e68833205894032b56b8156ea81f5ed","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d599c76865814a17bdeaa0fe97161fed","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5bccea80609a44368cff199c1ad43984","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37aa7875611b47668c5672ba2785b881","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9948211624745f29d82c58b1f738e76","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","source":"from utils import get_sentence_window_query_engine\n\nsentence_window_engine = \\\nget_sentence_window_query_engine(sentence_index)","metadata":{"height":81},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71a4b8e86ffd4b4cb4fc1a896130502c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d138f88bf2f45c88edea497780cf9aa","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06978693d33b48ddb27560a0de87e0c9","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41943cbde0504a87b4e4a70538cc6b2d","version_major":2,"version_minor":0},"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5447a7400e44ca1b5cc9b770d9d7102","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73da4be8dd9e4bffa5255bbe70c4b3d4","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","source":"output = sentence_window_engine.query(\n    \"How do you create your AI portfolio?\")\noutput.response","metadata":{"height":64},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":["'You create your AI portfolio by building a collection of projects that demonstrate a progression of skills in the field.'"]},"metadata":{}}]},{"cell_type":"markdown","source":"## Feedback functions","metadata":{}},{"cell_type":"code","source":"import nest_asyncio\n\nnest_asyncio.apply()","metadata":{"height":64,"id":"5KqV-IbQaZVB"},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from trulens_eval import OpenAI as fOpenAI\n\nprovider = fOpenAI()","metadata":{"height":64},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### 1. Answer Relevance","metadata":{}},{"cell_type":"code","source":"from trulens_eval import Feedback\n\nf_qa_relevance = Feedback(\n    provider.relevance_with_cot_reasons,\n    name=\"Answer Relevance\"\n).on_input_output()","metadata":{"height":115},"execution_count":11,"outputs":[{"name":"stdout","output_type":"stream","text":"âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n\nâœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"}]},{"cell_type":"markdown","source":"### 2. Context Relevance","metadata":{}},{"cell_type":"code","source":"from trulens_eval import TruLlama\n\ncontext_selection = TruLlama.select_source_nodes().node.text","metadata":{"height":64},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nf_qs_relevance = (\n    Feedback(provider.qs_relevance,\n             name=\"Context Relevance\")\n    .on_input()\n    .on(context_selection)\n    .aggregate(np.mean)\n)","metadata":{"height":166},"execution_count":13,"outputs":[{"name":"stdout","output_type":"stream","text":"âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n\nâœ… In Context Relevance, input statement will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"}]},{"cell_type":"code","source":"import numpy as np\n\nf_qs_relevance = (\n    Feedback(provider.qs_relevance_with_cot_reasons,\n             name=\"Context Relevance\")\n    .on_input()\n    .on(context_selection)\n    .aggregate(np.mean)\n)","metadata":{"height":166},"execution_count":14,"outputs":[{"name":"stdout","output_type":"stream","text":"âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n\nâœ… In Context Relevance, input statement will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"}]},{"cell_type":"markdown","source":"### 3. Groundedness","metadata":{}},{"cell_type":"code","source":"from trulens_eval.feedback import Groundedness\n\ngrounded = Groundedness(groundedness_provider=provider)","metadata":{"height":64},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"f_groundedness = (\n    Feedback(grounded.groundedness_measure_with_cot_reasons,\n             name=\"Groundedness\"\n            )\n    .on(context_selection)\n    .on_output()\n    .aggregate(grounded.grounded_statements_aggregator)\n)","metadata":{"height":149,"id":"kXJBD4gfaZVC"},"execution_count":16,"outputs":[{"name":"stdout","output_type":"stream","text":"âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n\nâœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"}]},{"cell_type":"markdown","source":"## Evaluation of the RAG application","metadata":{}},{"cell_type":"code","source":"from trulens_eval import TruLlama\nfrom trulens_eval import FeedbackMode\n\ntru_recorder = TruLlama(\n    sentence_window_engine,\n    app_id=\"App_1\",\n    feedbacks=[\n        f_qa_relevance,\n        f_qs_relevance,\n        f_groundedness\n    ]\n)","metadata":{"height":217,"id":"KUDHInR-aZVC"},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"eval_questions = []\nwith open('eval_questions.txt', 'r') as file:\n    for line in file:\n        # Remove newline character and convert to integer\n        item = line.strip()\n        eval_questions.append(item)","metadata":{"height":115,"id":"dsA3ziw1aZVD"},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"eval_questions","metadata":{"height":30},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":["['What are the keys to building a career in AI?',\n"," 'How can teamwork contribute to success in AI?',\n"," 'What is the importance of networking in AI?',\n"," 'What are some good habits to develop for a successful career?',\n"," 'How can altruism be beneficial in building a career?',\n"," 'What is imposter syndrome and how does it relate to AI?',\n"," 'Who are some accomplished individuals who have experienced imposter syndrome?',\n"," 'What is the first step to becoming good at AI?',\n"," 'What are some common challenges in AI?',\n"," 'Is it normal to find parts of AI challenging?']"]},"metadata":{}}]},{"cell_type":"code","source":"eval_questions.append(\"How can I be successful in AI?\")","metadata":{"height":30},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"eval_questions","metadata":{"height":30},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for question in eval_questions:\n    with tru_recorder as recording:\n        sentence_window_engine.query(question)","metadata":{"height":64,"id":"01_P6TxaaZVD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"records, feedback = tru.get_records_and_feedback(app_ids=[])\nrecords.head()","metadata":{"height":47,"id":"sNPhDde6ZArq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\npd.set_option(\"display.max_colwidth\", None)\nrecords[[\"input\", \"output\"] + feedback]","metadata":{"height":81},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tru.get_leaderboard(app_ids=[])","metadata":{"height":30},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tru.run_dashboard()","metadata":{"height":30,"id":"6Yp4_e4faZVD"},"execution_count":null,"outputs":[]}]}